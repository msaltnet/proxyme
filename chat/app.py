import datetime
import json
import os
from typing import Dict, List

import streamlit as st
from dotenv import load_dotenv

from config import ChatBotConfig
from core import InputProcessor, ResponseFormatter

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from services import LLMService
from utils import (
    create_download_button,
    create_upload_widget,
    export_conversation_to_json,
    get_conversation_stats,
    validate_json_import,
)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì„¤ì • ë¡œë“œ
config = ChatBotConfig()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title=config.get("ui.page_title"),
    page_icon=config.get("ui.page_icon"),
    layout=config.get("ui.layout"),
    initial_sidebar_state=config.get("ui.sidebar_state"),
)


class ChatBot:
    def __init__(self):
        # LLM ì„¤ì •ì—ì„œ í•„ìš”í•œ ê°’ë“¤ ê°€ì ¸ì˜¤ê¸°
        llm_config = config.get("llm", {})

        # LiteLLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.llm_service = LLMService(model=llm_config.get("model", "gpt-3.5-turbo"))

        self.input_processor = InputProcessor()
        self.response_formatter = ResponseFormatter()

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        system_prompt = config.get("system_prompt")
        if system_prompt:
            self.llm_service.set_system_prompt(system_prompt)

    def get_llm_response(self, user_input: str) -> str:
        """LLMì„ í†µí•´ ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±"""
        try:
            # LLM íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
            llm_params = config.get("llm", {})

            # LLM ì„œë¹„ìŠ¤ë¥¼ í†µí•´ ì‘ë‹µ ìƒì„±
            response = self.llm_service.get_response(user_input, **llm_params)
            return response

        except Exception as e:
            st.error(f"LLM ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def clear_history(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        self.llm_service.clear_history()

    def get_conversation_history(self) -> List[Dict[str, str]]:
        """ëŒ€í™” ê¸°ë¡ ë°˜í™˜"""
        return self.llm_service.get_history()

    def export_conversation(self) -> str:
        """ëŒ€í™” ê¸°ë¡ ë‚´ë³´ë‚´ê¸°"""
        return self.llm_service.export_conversation()

    def import_conversation(self, conversation_json: str):
        """ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°"""
        self.llm_service.import_conversation(conversation_json)


def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if "chatbot" not in st.session_state:
        st.session_state.chatbot = ChatBot()

    if "messages" not in st.session_state:
        st.session_state.messages = []


def render_chat_interface():
    """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""
    st.title("ğŸ¤– ProxyMe ChatBot")
    st.markdown("---")

    # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ ì˜ì—­
    chat_container = st.container()

    # ë©”ì‹œì§€ í‘œì‹œ
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})

        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("user"):
            st.markdown(prompt)

        # ë´‡ ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
        with st.chat_message("assistant"):
            with st.spinner("ì‘ë‹µì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                response = st.session_state.chatbot.get_llm_response(prompt)
                st.markdown(response)

        # ë´‡ ì‘ë‹µì„ ë©”ì‹œì§€ì— ì¶”ê°€
        st.session_state.messages.append({"role": "assistant", "content": response})


def render_sidebar():
    """ì‚¬ì´ë“œë°” ë Œë”ë§"""
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")

        # API í‚¤ í™•ì¸
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            st.success("âœ… OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤")
        else:
            st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            st.info("chat/.env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”")

        st.markdown("---")

        # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
        st.subheader("ğŸ’¬ ëŒ€í™” ê´€ë¦¬")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ ì´ˆê¸°í™”", type="secondary"):
                st.session_state.chatbot.clear_history()
                st.session_state.messages = []
                st.rerun()

        with col2:
            if st.button("ğŸ“Š í†µê³„"):
                stats = get_conversation_stats(st.session_state.messages)
                st.json(stats)

        # ëŒ€í™” ë‚´ë³´ë‚´ê¸°/ê°€ì ¸ì˜¤ê¸°
        st.subheader("ğŸ“ ëŒ€í™” íŒŒì¼")

        # ë‚´ë³´ë‚´ê¸°
        if st.session_state.messages:
            export_data = export_conversation_to_json(st.session_state.messages)
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            create_download_button(
                export_data,
                f"conversation_{timestamp}.json",
                "application/json",
            )

        # ê°€ì ¸ì˜¤ê¸°
        uploaded_file = create_upload_widget([".json"], "conversation_upload")
        if uploaded_file is not None:
            try:
                content = uploaded_file.read().decode("utf-8")
                if validate_json_import(content):
                    data = json.loads(content)
                    if "messages" in data:
                        st.session_state.messages = data["messages"]
                        st.session_state.chatbot.import_conversation(content)
                        st.success("ëŒ€í™”ê°€ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™€ì¡ŒìŠµë‹ˆë‹¤!")
                        st.rerun()
                    else:
                        st.error("ì˜¬ë°”ë¥¸ ëŒ€í™” íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.")
                else:
                    st.error("ì˜ëª»ëœ JSON í˜•ì‹ì…ë‹ˆë‹¤.")
            except (UnicodeDecodeError, json.JSONDecodeError) as e:
                st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")

        st.markdown("---")

        # ëŒ€í™” ê¸°ë¡ ì •ë³´
        st.subheader("ğŸ“Š ëŒ€í™” ì •ë³´")
        stats = get_conversation_stats(st.session_state.messages)
        st.write(f"ì´ ë©”ì‹œì§€: {stats['total_messages']}")
        st.write(f"ì‚¬ìš©ì: {stats['user_messages']}")
        st.write(f"AI: {stats['assistant_messages']}")

        # LLM ì„¤ì • ì •ë³´
        st.subheader("ğŸ¤– LLM ì„¤ì •")
        llm_config = config.get("llm", {})
        st.write(f"ëª¨ë¸: {llm_config.get('model', 'N/A')}")
        st.write(f"ìµœëŒ€ í† í°: {llm_config.get('max_tokens', 'N/A')}")
        st.write(f"ì˜¨ë„: {llm_config.get('temperature', 'N/A')}")

        st.markdown("---")

        # í–¥í›„ ê¸°ëŠ¥ ì•ˆë‚´
        st.subheader("ğŸš€ í–¥í›„ ê¸°ëŠ¥")
        features = config.get("features", {})

        enabled_features = []
        disabled_features = []

        for feature, enabled in features.items():
            if enabled:
                enabled_features.append(f"âœ… {feature}")
            else:
                disabled_features.append(f"â³ {feature}")

        if enabled_features:
            st.success("\n".join(enabled_features))

        if disabled_features:
            st.info("\n".join(disabled_features))


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    initialize_session_state()

    # ì‚¬ì´ë“œë°” ë Œë”ë§
    render_sidebar()

    # ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§
    render_chat_interface()


if __name__ == "__main__":
    main()
